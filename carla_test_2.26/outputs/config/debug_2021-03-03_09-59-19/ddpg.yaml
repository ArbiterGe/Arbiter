agent: ddpg
num_updates: 5000
lr: 0.1 # Learning rate
base_rl: 0.001
eps: 1e-08 # RMSprop optimizer epsilon
alpha: 0.99 # RMSProp alpha
gamma: 0.99 # Discount factor for rewards
batch_size: 256 
use_gae: False # Use generalized advantage estimation
tau: 0.95 # GAE parameter
action_type: carla-original # carla-original or continuous
entropy_coef: 0.01
value_loss_coef: 0.5
max_grad_norm: 0.5 # Max norm of the gradients
seed: 1 # Random seed
num_processes: 8 # Number of processes to use for training.
num_steps: 250
replay_size: 131072
polyak: 0.99

# PPO-specific parameters
ppo_epoch: 4
num_mini_batch: 16 # Number of mini-batches for PPO
clip_param: 0.2 # PPO clip parameter
act_noise: 0.75

reward_class: CarlaReward
